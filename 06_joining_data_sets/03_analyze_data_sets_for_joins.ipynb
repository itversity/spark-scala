{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Datasets for Joins\n",
    "\n",
    "Let us analyze data sets that are going to be used for joins.\n",
    "* We will use January 2008 airlines data which have all relevant flight details.\n",
    "* Let us read and review the airlines data quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided.\n",
    "\n",
    "If you want to use terminal for the practice, here is the command to use.\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "  --master yarn \\\n",
    "  --name \"Joining Data Sets\" \\\n",
    "  --conf spark.ui.port=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    appName(\"Joining Data Sets\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = spark.\n",
    "    read.\n",
    "    parquet(\"/public/airlines_all/airlines-part/flightmonth=200801\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will be using another data set to get details about airports. Details include information such as State, City etc for a given airport code.\n",
    "* Let us analyze the Dataset to confirm if there is header and also how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.\n",
    "    read.\n",
    "    text(airportCodesPath).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Data is tab separated.\n",
    " * There is header for the data set.\n",
    " * Dataset have 4 fields - **Country, State, City, IATA**\n",
    "    \n",
    "    \n",
    "Create DataFrame airport_codes applying appropriate Schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodes = spark.\n",
    "    read.\n",
    "    option(\"sep\", \"\\t\").\n",
    "    option(\"header\", true).\n",
    "    option(\"inferSchema\", true).\n",
    "    csv(airportCodesPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preview and Understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get schema of **airport_codes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the count of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Get the count of unique records and see if it is the same as total count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    select(\"IATA\").\n",
    "    distinct.\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * If they are not equal, analyze the data and identify IATA codes which are repeated more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lit, count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val duplicateIATACount = airportCodes.\n",
    "    groupBy(\"IATA\").\n",
    "    agg(count(lit(1)).alias(\"iata_count\")).\n",
    "    filter(\"iata_count > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateIATACount.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Filter out the duplicates using the most appropriate one and discard others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"IATA = 'Big'\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big')\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big')\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Get number of airports (IATA Codes) for each state in the US. Sort the data in descending order by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodes = spark.\n",
    "    read.\n",
    "    option(\"sep\", \"\\t\").\n",
    "    option(\"header\", true).\n",
    "    option(\"inferSchema\", true).\n",
    "    csv(airportCodesPath).\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big') AND Country = 'USA'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{count, col, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCountByState = airportCodes.\n",
    "    groupBy(\"Country\", \"State\").\n",
    "    agg(count(lit(1)).alias(\"IATACount\")).\n",
    "    orderBy(col(\"IATACount\").desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCountByState.show(51)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
