{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Data Sets\n",
    "\n",
    "Let us understand how to join multiple Data Sets using Spark based APIs.\n",
    "* Prepare Datasets for Joins\n",
    "* Starting Spark Context\n",
    "* Analyze Datasets for Joins\n",
    "* Problem Statements\n",
    "* Overview of Joins\n",
    "* Solutions - Problem 1\n",
    "* Solutions - Problem 2\n",
    "* Solutions - Problem 3\n",
    "* Solutions - Problem 4\n",
    "* Solutions - Problem 5\n",
    "* Solutions - Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Joins\n",
    "Let us prepare datasets to join.\n",
    "\n",
    "* Make sure airport-codes is in HDFS.\n",
    "* We will also use airlines data for the month of January 2008. We have used that data set in the past as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"hdfs dfs -ls /public/airlines_all\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"hdfs dfs -ls /public/airlines_all/airport-codes\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "\n",
    "\"hdfs dfs -ls /public/airlines_all/airlines-part/flightmonth=200801\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark Context\n",
    "\n",
    "Let us start spark context for this Notebook so that we can execute the code provided.\n",
    "\n",
    "If you want to use terminal for the practice, here is the command to use.\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "  --master yarn \\\n",
    "  --name \"Joining Data Sets\" \\\n",
    "  --conf spark.ui.port=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    appName(\"Joining Data Sets\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Datasets for Joins\n",
    "\n",
    "Let us analyze data sets that are going to be used for joins.\n",
    "* We will use January 2008 airlines data which have all relevant flight details.\n",
    "* Let us read and review the airlines data quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = spark.\n",
    "    read.\n",
    "    parquet(\"/public/airlines_all/airlines-part/flightmonth=200801\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will be using another data set to get details about airports. Details include information such as State, City etc for a given airport code.\n",
    "* Let us analyze the Dataset to confirm if there is header and also how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.\n",
    "    read.\n",
    "    text(airportCodesPath).\n",
    "    show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Data is tab separated.\n",
    " * There is header for the data set.\n",
    " * Dataset have 4 fields - **Country, State, City, IATA**\n",
    "    \n",
    "    \n",
    "Create DataFrame airport_codes applying appropriate Schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodes = spark.\n",
    "    read.\n",
    "    option(\"sep\", \"\\t\").\n",
    "    option(\"header\", true).\n",
    "    option(\"inferSchema\", true).\n",
    "    csv(airportCodesPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Preview and Understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get schema of **airport_codes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the count of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Get the count of unique records and see if it is the same as total count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    select(\"IATA\").\n",
    "    distinct.\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * If they are not equal, analyze the data and identify IATA codes which are repeated more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{lit, count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val duplicateIATACount = airportCodes.\n",
    "    groupBy(\"IATA\").\n",
    "    agg(count(lit(1)).alias(\"iata_count\")).\n",
    "    filter(\"iata_count > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateIATACount.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Filter out the duplicates using the most appropriate one and discard others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"IATA = 'Big'\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big')\").\n",
    "    show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big')\").\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Get number of airports (IATA Codes) for each state in the US. Sort the data in descending order by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodesPath = \"/public/airlines_all/airport-codes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCodes = spark.\n",
    "    read.\n",
    "    option(\"sep\", \"\\t\").\n",
    "    option(\"header\", true).\n",
    "    option(\"inferSchema\", true).\n",
    "    csv(airportCodesPath).\n",
    "    filter(\"!(State = 'Hawaii' AND IATA = 'Big') AND Country = 'USA'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCodes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{count, col, lit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airportCountByState = airportCodes.\n",
    "    groupBy(\"Country\", \"State\").\n",
    "    agg(count(lit(1)).alias(\"IATACount\")).\n",
    "    orderBy(col(\"IATACount\").desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCountByState.show(51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statements\n",
    "\n",
    "Let us understand how to join Data Frames by using some problem statements. We will use 2008 January airlines data along with Airport Codes.\n",
    "\n",
    "* Get number of flights departed from each of the US airport.\n",
    "* Get number of flights departed from each of the state.\n",
    "* Get the list of airports in the US from which flights are not departed.\n",
    "* Check if there are any origins in airlines data which do not have record in airport-codes.\n",
    "* Get the total number of flights from the airports that do not contain entries in airport-codes.\n",
    "* Get the total number of flights per airport that do not contain entries in airport-codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Joins\n",
    "\n",
    "Let us get an overview of joining Data Frames.\n",
    "* Our data cannot be stored in one table. It will be stored in multiple tables and the tables might be related.\n",
    "  * When it comes to transactional systems, we typically define tables based on Normalization Principles.\n",
    "  * When it comes to data warehousing applications, we typically define tables using Dimensional Modeling.\n",
    "  * Either of the approach data is scattered into multiple tables and relationships are defined.\n",
    "  * Typically tables are related with one to one, one to many, many to many relationships.\n",
    "* When we have 2 Data Sets that are related based on a common key we typically perform join.\n",
    "* There are different types of joins.\n",
    "  * INNER JOIN\n",
    "  * OUTER JOIN (LEFT or RIGHT)\n",
    "  * FULL OUTER JOIN (a LEFT OUTER JOIN b UNION a RIGHT OUTER JOIN b)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
