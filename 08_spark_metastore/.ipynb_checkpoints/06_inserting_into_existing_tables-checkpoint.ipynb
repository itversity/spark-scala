{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting into Existing Tables\n",
    "\n",
    "Let us understand how we can insert data into existing tables using `insertInto`.\n",
    "\n",
    "* We can use modes such as `append` and `overwrite` with `insertInto`. Default is `append`.\n",
    "* When we use `insertInto`, following happens:\n",
    "  * If the table does not exist, `insertInto` will throw an exception.\n",
    "  * If the table exists, by default data will be appended.\n",
    "  * We can alter the behavior by using keyword argument overwrite. It is by default False, we can pass True to replace existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided.\n",
    "\n",
    "If you want to use terminal for the practice, here is the command to use.\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "  --master yarn \\\n",
    "  --name \"Joining Data Sets\" \\\n",
    "  --conf spark.ui.port=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    appName(\"Spark Metastore\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Let us perform few tasks to understand how to write a Data Frame into existing tables in the Metastore.\n",
    "\n",
    "* Make sure hr_db database and employees table in hr_db are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(f\"{username}_hr_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use employees Data Frame and insert data into the employees table in hr_db database. Make sure existing data is overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = [(1, \"Scott\", \"Tiger\", 1000.0, \"united states\"),\n",
    "             (2, \"Henry\", \"Ford\", 1250.0, \"India\"),\n",
    "             (3, \"Nick\", \"Junior\", 750.0, \"united KINGDOM\"),\n",
    "             (4, \"Bill\", \"Gomes\", 1500.0, \"AUSTRALIA\")\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF = spark.createDataFrame(employees,\n",
    "    schema=\"\"\"employee_id INT, first_name STRING, last_name STRING,\n",
    "              salary FLOAT, nationality STRING\n",
    "           \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF.write.insertInto(\"employees\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.table(\"employees\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
