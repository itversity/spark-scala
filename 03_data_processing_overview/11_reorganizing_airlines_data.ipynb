{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorganizing airlines data\n",
    "\n",
    "Let us reorganize our airlines data to fewer files where data is compressed and also partitioned by Month.\n",
    "* We have ~1920 files of ~64MB Size.\n",
    "* Data is in the range of 1987 October and 2008 December (255 months)\n",
    "* By default it uses ~1920 threads to process the data and it might end up with too many small files. We can avoid that by using repartition and then partition by the month.\n",
    "* Here are the steps we are going to follow to partition by flight month and save the data to /user/[YOUR_USER_NAME]/airlines.\n",
    "  * Read one file first and get the schema.\n",
    "  * Read the entire data by applying the schema from the previous step.\n",
    "  * Add additional column flightmonth using withColumn by using lpad on month column and concat functions. We need to do this as the month in our data set is of type integer and we want to pad with 0 for months till september to format it into YYYYMM.\n",
    "  * Repartition the data into 255 based on the number of months using flightmonth\n",
    "  * Partition the data by partitionBy while writing the data to the target location.\n",
    "  * We will use parquet file format which will automatically compresses data using Snappy algorithm.\n",
    " \n",
    "**This process will take time, once it is done we will review the target location to which data is copied by partitioning using month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.dynamicAllocation.enabled\", \"false\").\n",
    "    config(\"spark.executor.instances\", 40).\n",
    "    appName(\"Data Processing - Overview\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions. {concat, lpad}\n",
    "\n",
    "val airlines_schema = spark.read.\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"inferSchema\", \"true\").\n",
    "    csv(\"/public/airlines_all/airlines/part-00000\").\n",
    "    schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val airlines = spark.\n",
    "    read.\n",
    "    option(\"header\", \"true\").\n",
    "    schema(airlines_schema).\n",
    "    csv(\"/public/airlines_all/airlines/part*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"255\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val username = System.getProperty(\"user.name\")\n",
    "\n",
    "airlines.\n",
    "    distinct.\n",
    "    withColumn(\"flightmonth\", concat($\"year\", lpad($\"month\", 2, \"0\"))).\n",
    "    repartition(255, $\"flightmonth\").\n",
    "    write.\n",
    "    mode(\"overwrite\").\n",
    "    partitionBy(\"flightmonth\").\n",
    "    format(\"parquet\").\n",
    "    save(s\"/user/${username}/airlines-part\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
